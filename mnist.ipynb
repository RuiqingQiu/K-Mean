{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, struct\n",
    "from array import array as pyarray\n",
    "import numpy as np\n",
    "from scipy.cluster.vq import *\n",
    "from numpy import append, array, int8, uint8, zeros\n",
    "from pylab import *\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "class Data(object):\n",
    "    # N points, k cluster, p dimensions\n",
    "    def __init__(self, N, k, p):\n",
    "        self.N = N\n",
    "        self.k = k\n",
    "        self.p = p\n",
    "        self.true_center = []\n",
    "        self.true_cluster_list = []\n",
    "        self.data_set = []\n",
    "        self.PIs = []\n",
    "        self.means = []\n",
    "        self.sigma = 0.0\n",
    "\n",
    "    def init_board_gauss(self):\n",
    "        n = float(self.N)/self.k\n",
    "        X = []\n",
    "        for i in range(self.k):\n",
    "            c = ()\n",
    "            # construct a random center point\n",
    "            for j in range(self.p):\n",
    "                c = c + (random.uniform(-1,1),)\n",
    "            self.true_center.append(c)\n",
    "            #s = random.uniform(0.05,0.5)\n",
    "            s = 0.05\n",
    "            x = []\n",
    "            while len(x) < n:\n",
    "                # need to change dimension\n",
    "                lst = []\n",
    "                for i in c:\n",
    "                    lst.append(np.random.normal(i,s))\n",
    "                point = np.array(lst)\n",
    "                good = True\n",
    "                for i in point:\n",
    "                    if abs(i) >= 1:\n",
    "                        good = False\n",
    "                if good:\n",
    "                    x.append(point)\n",
    "            X.extend(x)\n",
    "        X = np.array(X)[:self.N]\n",
    "        return X\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data_set = data\n",
    "    # Taking in true center list, and the result center list\n",
    "    def error_calculate(self,res):\n",
    "        error = 0.0\n",
    "        for i in range(self.k):\n",
    "            min_dis = distance.euclidean(self.true_center[i],res[0])\n",
    "            for j in range(self.k):\n",
    "                # calculate the distance btw true center and kmean center\n",
    "                dst = distance.euclidean(self.true_center[i],res[j])\n",
    "                # find the minimum dst btw the true center and kmean center\n",
    "                if dst < min_dis:\n",
    "                    min_dis = dst\n",
    "            error += min_dis * min_dis\n",
    "        # print \"the error rate is: \", error\n",
    "        return math.sqrt(error / (self.sigma * self.sigma * self.p))\n",
    "\n",
    "    # calculate the true function enables more kmean center than true center\n",
    "    # this is for the true center \n",
    "    def true_cost_function(self):\n",
    "        cost = 0.0\n",
    "        # loop through the data set\n",
    "        for data in self.data_set:\n",
    "            # min_dist is the distance to the first true center\n",
    "            min_dis = distance.euclidean(data,self.true_center[0])\n",
    "            # loop through the true center\n",
    "            for i in range(self.k):\n",
    "                 # calculate the distance btw true center and kmean center\n",
    "                dst = distance.euclidean(data,self.true_center[i])\n",
    "                # find the minimum dst btw the true center and kmean center\n",
    "                if dst < min_dis:\n",
    "                    min_dis = dst\n",
    "            cost += min_dis * min_dis\n",
    "        return cost\n",
    "    \n",
    "    # this is for the cost function compared to the true center cost function\n",
    "    def cost_function(self,res):\n",
    "        cost = 0.0\n",
    "        # loop through the whole dataset\n",
    "        for data in self.data_set:\n",
    "            min_dis = distance.euclidean(data,res[0])\n",
    "            for i in range(len(res)):\n",
    "                 # calculate the distance btw true center and kmean center\n",
    "                dst = distance.euclidean(data,res[i])\n",
    "                # find the minimum dst btw the true center and kmean center\n",
    "                if dst < min_dis:\n",
    "                    min_dis = dst\n",
    "            cost += min_dis * min_dis\n",
    "        # the ratio of result center cost/ true center cost\n",
    "        return cost/self.true_cost_function()\n",
    "            \n",
    "\n",
    "    def set_true_center(self, means):\n",
    "        self.true_center = means\n",
    "        \n",
    "        #print \"true center is \", self.true_center\n",
    "\n",
    "\n",
    "    # mean is a p dimensional vector, covarience is a p*p matrix\n",
    "    # number_of_sample is n samples\n",
    "    # return value: n*p matrix, generate n samples from N(mean,covarience)\n",
    "    def generate_mult_normal_data(self, mean, covariance, num_of_samples):\n",
    "        return np.random.multivariate_normal(mean,covariance, num_of_samples)\n",
    "\n",
    "    # prob is list of probability that sums to 1\n",
    "    # means is a p dimensional vector,covarience is a p*p matrix\n",
    "    # number_of_samples is n samples\n",
    "    # return value: generate n samples from the mixture of Gaussian\n",
    "    def generate_mult_normal_based_prob(self, prob, means, covariance, num_of_samples):\n",
    "        data_list = []\n",
    "        # keep track which points belong to which cluster\n",
    "        true_cluster_list = []\n",
    "        for i in range(num_of_samples):\n",
    "            # flip a coin to see which cluster the data point comes from\n",
    "            random_num = random.random()\n",
    "            sum = 0.0\n",
    "            index = -1\n",
    "            for p in prob:\n",
    "                if random_num < sum:\n",
    "                    break\n",
    "                sum += p\n",
    "                index = index + 1\n",
    "            true_cluster_list.append(index)\n",
    "            # call the generate_mult_normal_data rountine\n",
    "            data_list.append(self.generate_mult_normal_data(means[index], covariance,1)[0])\n",
    "        self.true_cluster_list = true_cluster_list\n",
    "        return np.array(data_list)[:num_of_samples]\n",
    "        #return (np.array(data_list)[:num_of_samples], true_cluster_list)\n",
    "    def generate_data(self, dimension, p_sigma, number_of_cluster, number_of_points):\n",
    "        # dimension\n",
    "        self.p = dimension\n",
    "\n",
    "        # sqrt of variance\n",
    "        self.sigma = p_sigma\n",
    "\n",
    "        # k is number of clusters\n",
    "        self.k = number_of_cluster\n",
    "\n",
    "        # n is number of points to be generated\n",
    "        self.N = number_of_points\n",
    "\n",
    "        # init a covariance matrix as identity matrix\n",
    "        self.identity_matrix = np.identity(self.p)\n",
    "\n",
    "        # covariance matrix\n",
    "        covariance = self.sigma * self.sigma * self.identity_matrix\n",
    "        # choose means from\n",
    "\n",
    "\n",
    "        # means are from a normal distribution with center is all 0s and varience N(0,sigma squre identity matrix)\n",
    "        mean = []\n",
    "        for i in range(self.p):\n",
    "            mean.append(0)\n",
    "        # choose means, k is the number of centers/cluster\n",
    "        self.means = self.generate_mult_normal_data(mean, covariance, self.k)\n",
    "\n",
    "        self.set_true_center(self.means)\n",
    "\n",
    "        # choose pis, ASA probabolity\n",
    "        self.PIs = []\n",
    "        for i in range(self.k):\n",
    "            # every cluster has the same probability\n",
    "            self.PIs.append(1.0/self.k)\n",
    "\n",
    "        # generate n points from the mixture model\n",
    "        self.data_set = self.generate_mult_normal_based_prob(self.PIs, self.means, covariance, self.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt \n",
    "mnist = fetch_mldata('MNIST original', data_home='./data')\n",
    "X_digits, _,_, Y_digits = mnist.values() # fetch dataset from internet\n",
    "images0 = []\n",
    "images1 = []\n",
    "images2 = []\n",
    "images3 = []\n",
    "images4 = []\n",
    "images5 = []\n",
    "images6 = []\n",
    "images7 = []\n",
    "images8 = []\n",
    "images9 = []\n",
    "for i in range(len(Y_digits)):\n",
    "    if Y_digits[i] == 0.0:\n",
    "        images0.append(X_digits[i])\n",
    "    elif Y_digits[i] == 1.0:\n",
    "        images1.append(X_digits[i])\n",
    "    elif Y_digits[i] == 2.0:\n",
    "        images2.append(X_digits[i])\n",
    "    elif Y_digits[i] == 3.0:\n",
    "        images3.append(X_digits[i])\n",
    "    elif Y_digits[i] == 4.0:\n",
    "        images4.append(X_digits[i])\n",
    "    elif Y_digits[i] == 5.0:\n",
    "        images5.append(X_digits[i])\n",
    "    elif Y_digits[i] == 6.0:\n",
    "        images6.append(X_digits[i])\n",
    "    elif Y_digits[i] == 7.0:\n",
    "        images7.append(X_digits[i])\n",
    "    elif Y_digits[i] == 8.0:\n",
    "        images8.append(X_digits[i])\n",
    "    elif Y_digits[i] == 9.0:\n",
    "        images9.append(X_digits[i])\n",
    "mnist_true_center1 = []\n",
    "mnist_true_center = []\n",
    "mnist_true_center.append(np.array(images0).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images1).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images2).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images3).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images4).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images5).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images6).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images7).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images8).mean(axis=0).reshape(28,28))\n",
    "mnist_true_center.append(np.array(images9).mean(axis=0).reshape(28,28))\n",
    "\n",
    "mnist_true_center1.append(np.array(images0).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images1).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images2).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images3).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images4).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images5).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images6).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images7).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images8).mean(axis=0))\n",
    "mnist_true_center1.append(np.array(images9).mean(axis=0))\n",
    "\n",
    "\n",
    "# imshow(mnist_true_center[0], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[1], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[2], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[3], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[4], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[5], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[6], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[7], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[8], cmap=cm.gray)\n",
    "# show()\n",
    "# imshow(mnist_true_center[9], cmap=cm.gray)\n",
    "# show()\n",
    "\n",
    "#X_digits, Y_digits = shuffle(X_digits,Y_digits) # shuffle dataset (which is     ordered!)\n",
    "X_digits = X_digits[-5000:]\n",
    "# plt.rc(\"image\", cmap=\"binary\") # use black/white palette for plotting\n",
    "# for i in xrange(15):\n",
    "#     plt.subplot(3,5,i+1)\n",
    "#     plt.imshow(X_digits[10+i].reshape(28,28))\n",
    "#     plt.xticks(())\n",
    "#     plt.yticks(())\n",
    "# plt.show()\n",
    "\n",
    "# # classify to 10 clusters\n",
    "# kmeans = KMeans(10)\n",
    "# mu_digits = kmeans.fit(X_digits).cluster_centers_\n",
    "\n",
    "# plt.figure(figsize=(16,6))\n",
    "# for i in xrange(2*(mu_digits.shape[0]/2)): # loop over all means\n",
    "#     plt.subplot(2,mu_digits.shape[0]/2,i+1)\n",
    "#     plt.imshow(mu_digits[i].reshape(28,28))\n",
    "#     plt.xticks(())\n",
    "#     plt.yticks(())\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"number of data is \", len(X_digits)\n",
    "print \"each points is in dimension \", len(X_digits[0])\n",
    "d2 = Data(len(X_digits), 10, len(X_digits[0]))\n",
    "d2.set_data(X_digits)\n",
    "d2.set_true_center(mnist_true_center1)\n",
    "# run 5 times\n",
    "cost_function_score = []\n",
    "for i in range (0,100):\n",
    "    # classify to 10 clusters\n",
    "    kmeans = KMeans(10)\n",
    "    print i\n",
    "    mu_digits = kmeans.fit(X_digits).cluster_centers_\n",
    "    cost_function_score.append(d2.cost_function(mu_digits))\n",
    "print cost_function_score\n",
    "# plot the histogram for the score\n",
    "plt.xlabel('Cost function results')\n",
    "plt.ylabel('Frequency of the cost function result')\n",
    "plt.title(r'Histogram of Kmean on MNIST dataset for 10 clusters')\n",
    "n, bins, patches = plt.hist(cost_function_score,20,normed=0,facecolor=\"Red\",alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "#print d2.cost_function(mu_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cluster MNIST to 15 clusters\n",
    "# run 5 times\n",
    "cost_function_score = []\n",
    "for i in range (0,5):\n",
    "    # classify to 10 clusters\n",
    "    kmeans = KMeans(15)\n",
    "    mu_digits = kmeans.fit(X_digits).cluster_centers_\n",
    "    cost_function_score.append(d2.cost_function(mu_digits))\n",
    "print cost_function_score\n",
    "# plot the histogram for the score\n",
    "plt.xlabel('Cost function results')\n",
    "plt.ylabel('Frequency of the cost function result')\n",
    "plt.title(r'Histogram of Kmean on MNIST dataset for 15 clusters')\n",
    "n, bins, patches = plt.hist(cost_function_score,20,normed=0,facecolor=\"Red\",alpha=0.75)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
